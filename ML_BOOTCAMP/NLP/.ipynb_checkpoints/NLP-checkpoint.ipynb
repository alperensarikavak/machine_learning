{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f160511c-b042-421b-9ffb-aedf9efb1584",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                 Comment Sentiment  \\\n",
      "0      lets not forget that apple pay in 2014 require...   neutral   \n",
      "1      here in nz 50 of retailers don’t even have con...  negative   \n",
      "2      i will forever acknowledge this channel with t...  positive   \n",
      "3      whenever i go to a place that doesn’t take app...  negative   \n",
      "4      apple pay is so convenient secure and easy to ...  positive   \n",
      "...                                                  ...       ...   \n",
      "18403  i really like the point about engineering tool...  positive   \n",
      "18404  i’ve just started exploring this field and thi...  positive   \n",
      "18405  excelente video con una pregunta filosófica pr...   neutral   \n",
      "18406  hey daniel just discovered your channel a coup...  positive   \n",
      "18407  this is great focus is key a playful approach ...  positive   \n",
      "\n",
      "       sentiment_encoded  \n",
      "0                      1  \n",
      "1                      0  \n",
      "2                      2  \n",
      "3                      0  \n",
      "4                      2  \n",
      "...                  ...  \n",
      "18403                  2  \n",
      "18404                  2  \n",
      "18405                  1  \n",
      "18406                  2  \n",
      "18407                  2  \n",
      "\n",
      "[18408 rows x 3 columns]\n",
      "       sentiment_encoded\n",
      "0                      1\n",
      "1                      0\n",
      "2                      2\n",
      "3                      0\n",
      "4                      2\n",
      "...                  ...\n",
      "18403                  2\n",
      "18404                  2\n",
      "18405                  1\n",
      "18406                  2\n",
      "18407                  2\n",
      "\n",
      "[18408 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "\n",
    "dataset = pd.read_csv(\"YoutubeCommentsDataSet.csv\")\n",
    "\n",
    "df = dataset.copy()\n",
    "sentiment_map = {'negative': 0,'neutral': 1,'positive': 2}\n",
    "\n",
    "df['sentiment_encoded'] = df['Sentiment'].map(sentiment_map)\n",
    "\n",
    "\n",
    "\n",
    "print(df)\n",
    "df2 = df.iloc[:,2:]\n",
    "print(df2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "96851eb3-cd2e-421e-be1a-32f8692afb18",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\alper\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "comment = df.iloc[:,:1]\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "ps = PorterStemmer()\n",
    "\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b441b01d-6823-4bee-9bfb-1cc5794263f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\alper\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import CountVectorizer  # or TfidfVectorizer\n",
    "\n",
    "nltk.download('stopwords')\n",
    "ps = PorterStemmer()\n",
    "\n",
    "corpus = []\n",
    "new_labels = []  # to collect matching y values\n",
    "\n",
    "for i in range(len(comment)):\n",
    "    text = comment.iloc[i, 0]\n",
    "    if pd.isna(text):  # skip empty rows\n",
    "        continue\n",
    "    review = re.sub('[^a-zA-Z]', ' ', str(text))\n",
    "    review = review.lower()\n",
    "    review = review.split()\n",
    "    review = [ps.stem(word) for word in review if word not in stopwords.words('english')]\n",
    "    review = ' '.join(review)\n",
    "    if review.strip() != '':\n",
    "        corpus.append(review)\n",
    "        new_labels.append(df['sentiment_encoded'].iloc[i])\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "cv = CountVectorizer(max_features=2000)\n",
    "X = cv.fit_transform(corpus).toarray()\n",
    "y = np.array(new_labels)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b520c308-0bea-4369-90bd-8cced5316bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dd1db15f-737e-4f8a-8046-1c903700e4d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.714167585446527\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 261   28  178]\n",
      " [ 178  293  414]\n",
      " [ 118  121 2037]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "mnb = MultinomialNB()\n",
    "mnb.fit(X_train, y_train)\n",
    "\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "# Make predictions\n",
    "y_pred = mnb.predict(X_test)\n",
    "# Evaluation\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bf34706b-fec0-4ff2-b113-b830cb374593",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogReg Accuracy: 0.7378721058434399\n",
      "[[ 261   28  178]\n",
      " [ 178  293  414]\n",
      " [ 118  121 2037]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression(max_iter=1000)\n",
    "lr.fit(X_train, y_train)\n",
    "y_pred_lr = lr.predict(X_test)\n",
    "\n",
    "print(\"LogReg Accuracy:\", accuracy_score(y_test, y_pred_lr))\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "549ee807-6646-4eb1-aebf-719a68cb926f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy: 0.7331863285556781\n",
      "[[ 261   28  178]\n",
      " [ 178  293  414]\n",
      " [ 118  121 2037]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier(n_estimators=100)\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred_rf = rf.predict(X_test)\n",
    "\n",
    "print(\"Random Forest Accuracy:\", accuracy_score(y_test, y_pred_rf))\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
